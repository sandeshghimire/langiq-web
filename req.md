Based on the document provided, here are all the requirements split into LLM App Development and Model Training & Fine-tuning categories:

## LLM App Development Requirements

### Programming & Frameworks
• Proficiency in Python programming
• Experience with JavaScript/TypeScript and Node.js
• Strong skills in React for frontend development
• Experience with FastAPI and Flask for backend APIs
• Familiarity with PyTorch and TensorFlow frameworks
• Experience with HuggingFace libraries and ecosystem

### LLM Integration & APIs
• Experience with LLM APIs (OpenAI, Anthropic, Cohere)
• Familiarity with GPT-3.5/4, Claude, and other foundation models
• Experience with LLM providers and their APIs
• Knowledge of prompt engineering and optimization strategies
• Experience with LLM output validation and safety measures

### RAG & Vector Technologies
• Experience implementing RAG (Retrieval Augmented Generation) systems
• Proficiency with vector databases (Pinecone, Weaviate, Chroma, FAISS, Qdrant)
• Knowledge of semantic search and embeddings
• Experience with high-dimensional indexing and low-latency optimization
• Understanding of dense/sparse retrieval and ranking algorithms

### Agent Frameworks & Orchestration
• Experience with LangChain, LangGraph, AutoGen frameworks
• Knowledge of multi-agent systems and agent orchestration
• Experience with tool-use/function-calling (agentic) implementations
• Familiarity with chain-of-thought and prompt chaining
• Experience designing agent workflows with context management

### Cloud & Infrastructure (AWS Focus)
• Strong experience with AWS services (EC2, S3, Lambda, SageMaker, Bedrock)
• Experience with API Gateway (REST + WebSocket)
• Knowledge of DynamoDB, Aurora PostgreSQL, and S3
• Familiarity with CloudFormation/CDK and IAM roles/policies
• Experience with serverless architectures and AWS Well Architected principles
• Knowledge of containerization (Docker/Kubernetes)

### Data Processing & Pipelines
• Experience with data pipelines and ETL processes
• Knowledge of AWS Glue, Airflow (MWAA)
• Experience with structured and unstructured data processing
• Familiarity with document processing (PyMuPDF, Apache Tika)
• Experience with large-scale data ingestion and transformation

### Search & Database Technologies
• Experience with OpenSearch and Elasticsearch
• Knowledge of PostgreSQL and NoSQL databases
• Familiarity with knowledge graphs and semantic technologies (RDF, OWL, SPARQL)
• Experience with distributed data processing tools (Spark, Airflow, Kubeflow)

### Real-time & Streaming
• Experience with WebSocket interfaces for LLM streaming
• Knowledge of real-time data processing and streaming pipelines
• Experience with async programming and progressive response generation

### Authentication & Security
• Experience with SSO and secure access flows
• Knowledge of healthcare data privacy regulations (HIPAA)
• Understanding of security best practices for AI systems
• Familiarity with confidential computing and Trusted Execution Environments (TEEs)

### Evaluation & Testing
• Experience building model evaluation pipelines
• Knowledge of LLM evaluation metrics and benchmarking
• Experience with A/B testing and performance monitoring
• Familiarity with test automation frameworks for AI systems

## Model Training & Fine-tuning Requirements

### Model Customization & Training
• Experience with LLM fine-tuning principles and methods
• Knowledge of instruction tuning and RLHF (Reinforcement Learning from Human Feedback)
• Experience with parameter-efficient tuning (LoRA, PEFT)
• Familiarity with continual learning pipelines for LLMs
• Experience with domain-specific model optimization

### Training Infrastructure & Optimization
• Experience with distributed training workflows
• Knowledge of tensor, pipeline, and expert parallelism
• Familiarity with multi-node GPU cluster configuration
• Experience with training data curation, versioning, and lineage tracking
• Knowledge of model evaluation and bias mitigation techniques

### Performance Optimization & Inference
• Experience with inference optimization and quantization techniques
• Knowledge of model serving and deployment optimization
• Familiarity with speculative decoding and prefix caching
• Experience with multi-token prediction and LoRA fusion
• Understanding of latency and throughput optimization

### GPU Programming & Low-level Optimization
• Experience writing CUDA kernels and low-level GPU code
• Familiarity with Triton kernel development
• Knowledge of GPU architectures and performance profiling
• Experience with tools like Nsight for GPU debugging
• Understanding of memory optimization and kernel efficiency

### Advanced Training Techniques
• Experience with mixture of experts architectures
• Knowledge of multimodal model training (Vision-Language Models)
• Familiarity with reinforcement learning techniques for model improvement
• Experience with model distillation and compression techniques
• Understanding of federated learning and distributed training paradigms

### Training Frameworks & Tools
• Experience with vLLM, TensorRT-LLM, and TGI (Text Generation Inference)
• Familiarity with Ollama and GGUF model formats
• Knowledge of DeepSpeed for large-scale training
• Experience with model compilation and optimization (torch.compile)
• Understanding of communication backends like NCCL

### Research & Development
• Experience translating research into practical applications
• Knowledge of latest advancements in LLM architectures
• Familiarity with transformer architectures and attention mechanisms
• Understanding of tokenization, embeddings, and model architectures
• Experience with experimental design and hypothesis testing

### Specialized Domains
• Experience with medical/healthcare AI applications (FHIR, HL7, clinical notes)
• Knowledge of financial AI applications and regulatory compliance
• Familiarity with cybersecurity and threat intelligence applications
• Understanding of network infrastructure and automation use cases

### Education & Experience Requirements
• Advanced degree (MS/PhD) in Computer Science, ML, AI, or related field
• 3-10 years of professional experience in ML/AI engineering
• 1-5+ years hands-on experience with large language models
• Strong publication record or open-source contributions preferred
• AWS certifications (Machine Learning Specialty preferred)